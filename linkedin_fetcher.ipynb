{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "566b7a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ee6669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3731835443', '3748931980']\n"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "o={}\n",
    "k=[]\n",
    "headers={\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\"}\n",
    "target_url='https://www.linkedin.com/jobs/search?keywords=Python&location=India&geoId=102713980&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum={}'\n",
    "# the target link can be replaced with any desired job filter\n",
    "runs = 10\n",
    "for i in range(runs):\n",
    "    res = requests.get(target_url.format(i))\n",
    "    if res.status_code == 200:\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        job_data = soup.find(\"code\", id=\"currentJobId\")\n",
    "        if job_data:\n",
    "            content = job_data.string\n",
    "            if content:\n",
    "                job_id = content.strip()\n",
    "                l.append(job_id)\n",
    "l = list(set(l))\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8792cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lxml import html\n",
    "# def extract_text_from_xpath(url, xpaths):\n",
    "#     response = requests.get(url)\n",
    "#     if response.status_code == 200:\n",
    "#         tree = html.fromstring(response.content.decode('utf-8'))\n",
    "#         extracted_text = []\n",
    "#         for xpath in xpaths:\n",
    "#             elements = tree.xpath(xpath)\n",
    "#             if elements:\n",
    "#                 extracted_text.extend([element.text_content() for element in elements])\n",
    "#         return extracted_text\n",
    "#     else:\n",
    "#         print(f\"Failed to fetch the URL. Status code: {response.status_code}\")\n",
    "#         return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca98e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_url='https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/{}'\n",
    "#for j in range(0,len(l)):\n",
    "#    company_xpaths = [f'/html/body/li[{i}]/div/div[2]/h4/a' for i in range(26)]\n",
    "#    o['company'] = extract_text_from_xpath(target_url.format(l[j]), company_xpaths)\n",
    "#    location_xpaths = [f'/html/body/li[{i}]/div/div[2]/div/span' for i in range(26)]\n",
    "#    o['job-location'] = extract_text_from_xpath(target_url.format(l[j]), location_xpaths)\n",
    "#    title_xpaths = [f'/html/body/li[{i}]/div/div[2]/h3' for i in range(26)]\n",
    "#    o['job-title'] = extract_text_from_xpath(target_url.format(l[j]), title_xpaths)\n",
    "#    url_xpaths = [f'/html/body/li[{i}]/div/a' for i in range(26)]\n",
    "#    o['job-url'] = extract_text_from_xpath(target_url.format(l[j]), url_xpaths)\n",
    "#    k.append(o)\n",
    "\n",
    "#df = pd.DataFrame(k)\n",
    "#df.to_csv('linkedinjobs.csv', index=False, encoding='utf-8')\n",
    "#print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf2491d",
   "metadata": {},
   "source": [
    "xpath method didn't word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e3f06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'company': 'Infosys', 'job-title': 'Python Lead', 'job-location': 'Bengaluru East, Karnataka, India', 'job-url': 'https://in.linkedin.com/company/infosys?trk=public_jobs_topcard_logo'}, {'company': 'Sprinklr', 'job-title': 'Product Analyst', 'job-location': 'Gurgaon, Haryana, India', 'job-url': 'https://www.linkedin.com/company/sprinklr?trk=public_jobs_topcard_logo'}]\n"
     ]
    }
   ],
   "source": [
    "target_url='https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{}'\n",
    "\n",
    "# to prevent itself from scraping, linkedin keeps on updating its HTML code. So, the code below might not work in future and has to be updated\n",
    "\n",
    "pattern = r'for the(.*?)role at'\n",
    "    \n",
    "for j in range(0,len(l)):\n",
    "\n",
    "    resp = requests.get(target_url.format(l[j]))\n",
    "    soup=BeautifulSoup(resp.text,'html.parser')\n",
    "\n",
    "    try:\n",
    "        company = soup.find(\"p\", class_=\"sign-up-modal__sub-header\").text.strip()\n",
    "        o[\"company\"]=company.split('role at', 1)[1].strip()\n",
    "    except:\n",
    "        o[\"company\"]=None\n",
    "\n",
    "    try:\n",
    "        title = soup.find(\"p\", class_=\"sign-up-modal__sub-header\").text.strip()\n",
    "        o[\"job-title\"]=re.search(pattern, title).group(1).strip()\n",
    "    except:\n",
    "        o[\"job-title\"]=None\n",
    "\n",
    "    try:\n",
    "        o[\"job-location\"]=soup.find(\"span\", class_=\"topcard__flavor topcard__flavor--bullet\").text.strip()\n",
    "    except:\n",
    "        o[\"job-location\"]=None\n",
    "        \n",
    "    try:\n",
    "        o[\"job-url\"]=soup.a.get('href')\n",
    "    except:\n",
    "        o[\"job-url\"]=None\n",
    "\n",
    "    k.append(o)\n",
    "    o={}\n",
    "\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9fab9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\AppData\\Local\\Temp\\ipykernel_22344\\3298829081.py:17: DeprecationWarning: [Deprecated][in version 6.0.0]: Method signature's arguments 'range_name' and 'values' will change their order. We recommend using named arguments for minimal impact. In addition, the argument 'values' will be mandatory of type: 'List[List]'. (ex) Worksheet.update(values = [[]], range_name=) \n",
      "  worksheet.update(\"A1\", existing_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1Sxe3mhzOeH43QIRL2J5ozth3kS2z0gb-LMXXnX4T_Yw',\n",
       " 'updatedRange': 'Sheet1!A1:D2',\n",
       " 'updatedRows': 2,\n",
       " 'updatedColumns': 4,\n",
       " 'updatedCells': 8}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
    "\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(r'C:\\Users\\rohit\\Python\\skuad_assignment\\linkedin-fetcher-288b8b77c6bc.json', scope)\n",
    "\n",
    "gc = gspread.authorize(credentials)\n",
    "\n",
    "sheet = gc.open(\"linkedin_fetcher\")\n",
    "\n",
    "worksheet = sheet.get_worksheet(0)\n",
    "\n",
    "existing_data = worksheet.get_all_values()\n",
    "\n",
    "for item in k:\n",
    "    values = [item['company'], item['job-title'], item['job-location'], item['job-url']]\n",
    "    existing_data.append(values)\n",
    "\n",
    "worksheet.update(\"A1\", existing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68280a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
